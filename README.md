# Lesson

https://web.stanford.edu/~jurafsky/slp3/

	
Speech and Language Processing (3rd ed. draft)

Dan Jurafsky and James H. Martin

2020 August: We're finally back to our regular summer writing on the textbook!

What we're busily writing right now: new versions of Chapter 8 (bringing together POS and NER in one chapter), Chapters 9 (with transformers) and 10 (BERT) and (finally) the MT chapter (11)!

Plus a modernizing pass (and typo fixing, thanks to all of you!!!) on all the other chapters.

We'll update them here when they are ready, and then figure out what's next.

Thanks so much to all of you for the help! We are really really grateful!!!

Chapter

1:	Introduction

2:	Regular Expressions, Text Normalization, and Edit Distance

3:	Language Modeling with N-Grams

4:	Naive Bayes Classification and Sentiment

5:	Logistic Regression

6:	Vector Semantics and Embeddings	Vector

7:	Neural Nets and Neural Language Models

8:	Part-of-Speech Tagging

9:	Sequence Processing with Recurrent Networks

10:	Encoder-Decoder Models, Attention, and Contextual Embeddings

11:	Machine Translation

12:	Constituency Grammars

13:	Constituency Parsing

14:	Statistical Constituency Parsing

15:	Dependency Parsing

16:	Logical Representations of Sentence Meaning

17:	Computational Semantics and Semantic Parsing

18:	Information Extraction

19:	Word Senses and WordNet	

20:	Semantic Role Labeling and Argument Structure	SRL
21:	Lexicons for Sentiment, Affect, and Connotation
22:	Coreference Resolution
23:	Discourse Coherence
24:	Summarization
25:	Question Answering
26:	Dialog Systems and Chatbots	Dialog
27:	Phonetics
28:	Speech Processing
 
Appendix Chapters (likely just on the web)
A:	Hidden Markov Models
B:	Spelling Correction and the Noisy Channel
